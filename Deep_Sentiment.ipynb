{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Sentiment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3VEjxTL2Muq",
        "outputId": "5c374361-c99e-46d5-ac75-daad22c4628d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading Dataset - Preprocessing on the Tweets"
      ],
      "metadata": {
        "id": "WsQEXhGRNHAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_writing_marks(string):\n",
        "  for char in ['?','!','#','@',',','.','$','%','^','&','*',')','(','/','~','`','&','+','+','_',';',':',\"'\"]:\n",
        "    if char == '#':\n",
        "      replaced = \"Hashtag \"\n",
        "    elif  char == '@':\n",
        "      replaced = \"Atsign \"\n",
        "    else:\n",
        "      replaced = ''\n",
        "    string = string.replace(char, replaced)\n",
        "  return string\n",
        "\n",
        "def change_label(label):\n",
        "  if '0' in label:\n",
        "    label = 0\n",
        "  elif '2' in label:\n",
        "    label = 1\n",
        "  elif '4' in label:\n",
        "    label = 2\n",
        "  return label"
      ],
      "metadata": {
        "id": "FYUGZGQGU_mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = r'/content/drive/My Drive/Courses/DeepLearning/HW03/Q01/Datas/train.csv'\n",
        "test_data_dir = r'/content/drive/My Drive/Courses/DeepLearning/HW03/Q01/Datas/test.csv'\n",
        "data_train = []\n",
        "data_test = []\n",
        "words = []\n",
        "\n",
        "with open(train_data_dir, 'r') as csvfile:\n",
        "  csvreader = csv.reader(csvfile)\n",
        "  try:\n",
        "    for row in csvreader:\n",
        "      if 'http' in row[5]:\n",
        "        continue\n",
        "      else:\n",
        "        text = remove_writing_marks(row[5])\n",
        "        label = change_label(row[0])\n",
        "        data_train.append([label, text])\n",
        "\n",
        "        for word in text.split():\n",
        "          if word in words:\n",
        "            pass\n",
        "          else:\n",
        "            words.append(word)\n",
        "  except:\n",
        "      pass\n",
        "\n",
        "with open(test_data_dir, 'r') as csvfile:\n",
        "  csvreader = csv.reader(csvfile,)\n",
        "  try:\n",
        "    for row in csvreader:\n",
        "      text = remove_writing_marks(row[5])\n",
        "      label = change_label(row[0])\n",
        "      data_test.append([label, text])\n",
        "\n",
        "      for word in text.split():\n",
        "          if word in words:\n",
        "            pass\n",
        "          else:\n",
        "            words.append(word)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "word_to_ix = {word: i for i, word in enumerate(words)}\n",
        "word_to_ix[' '] = len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdoHp4wK41aV",
        "outputId": "b65d0b79-dfe7-4752-caba-156692620565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text Embedding"
      ],
      "metadata": {
        "id": "uCvksXWHcKiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "with open('/content/drive/My Drive/Courses/DeepLearning/HW03/Q01/words_dict.pkl', 'wb') as f:\n",
        "    pickle.dump(word_to_ix, f)\n",
        "\n",
        "with open('/content/drive/My Drive/Courses/DeepLearning/HW03/Q01/data_test.pkl', 'wb') as f:\n",
        "    pickle.dump(data_test, f)\n",
        "\n",
        "with open('/content/drive/My Drive/Courses/DeepLearning/HW03/Q01/data_train.pkl', 'wb') as f:\n",
        "    pickle.dump(data_train, f)"
      ],
      "metadata": {
        "id": "JMVw332h06G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "with open('/content/drive/My Drive/Courses/DeepLearning/HW03/Q01/words_dict.pkl', 'rb') as f:\n",
        "    word_to_ix = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/My Drive/Courses/DeepLearning/HW03/Q01/data_test.pkl', 'rb') as f:\n",
        "    data_test = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/My Drive/Courses/DeepLearning/HW03/Q01/data_train.pkl', 'rb') as f:\n",
        "    data_train = pickle.load(f)"
      ],
      "metadata": {
        "id": "bUHA1RoOI7iW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding_dim = 203379\n",
        "vocab_size = 38\n",
        "\n",
        "for data in data_train:\n",
        "  Size = len(data[1])\n",
        "  if Size < vocab_size:\n",
        "    for i in range(vocab_size-Size):\n",
        "      data[1].append(' ')\n",
        "\n",
        "for data in data_test:\n",
        "  data[1] = data[1].split()\n",
        "  Size = len(data[1])\n",
        "  if Size < vocab_size:\n",
        "    for i in range(vocab_size-Size):\n",
        "      data[1].append(' ')"
      ],
      "metadata": {
        "id": "ooQwTWFSbzrv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = nn.Embedding(embedding_dim, vocab_size)"
      ],
      "metadata": {
        "id": "P1Gp8QA432D-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = data_test[19][1]\n",
        "context = [word_to_ix[w] for w in context]\n",
        "context = torch.tensor(context, dtype=torch.long)\n",
        "embeddings(context)"
      ],
      "metadata": {
        "id": "3_L5C0X98Hj7",
        "outputId": "62b26f54-3f3a-43cb-b4f0-d1cc545f9f9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.2178e-02,  9.8350e-01,  1.3378e+00,  ..., -6.1217e-04,\n",
              "          1.5526e+00, -9.2554e-01],\n",
              "        [-1.8072e+00,  1.9737e-01,  2.3170e-02,  ...,  9.1976e-01,\n",
              "         -1.9582e+00, -9.0427e-01],\n",
              "        [-4.0210e-01,  5.7361e-01,  7.9091e-01,  ..., -4.0950e-01,\n",
              "         -6.2774e-02,  1.0174e-01],\n",
              "        ...,\n",
              "        [ 5.6288e-01,  5.5102e-01, -4.8822e-01,  ..., -6.3118e-01,\n",
              "          3.0253e-01,  4.2783e-01],\n",
              "        [ 5.6288e-01,  5.5102e-01, -4.8822e-01,  ..., -6.3118e-01,\n",
              "          3.0253e-01,  4.2783e-01],\n",
              "        [ 5.6288e-01,  5.5102e-01, -4.8822e-01,  ..., -6.3118e-01,\n",
              "          3.0253e-01,  4.2783e-01]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "metadata": {
        "id": "ZKPutv4N_oa3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        packed_input = pack_padded_sequence(embeds, self.vocab_size, batch_first=True, enforce_sorted=False)\n",
        "        packed_output, _ = self.lstm(packed_input)\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "        tag_space = self.hidden2tag(output)\n",
        "        tag_scores = F.softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "fI5q_FxVgdsy"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "model = LSTMTagger(embedding_dim, 150, len(word_to_ix), 3)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "XMZR0266hO2z"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = prepare_sequence(data_train[10000][1], word_to_ix)\n",
        "emb = nn.Embedding(len(word_to_ix), embedding_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4F0L-C6h0XI",
        "outputId": "edb41ff1-64eb-4b82-db7e-e2b3c235bf15"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 38])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    inputs = prepare_sequence(data_train[0][1], word_to_ix)\n",
        "    tag_scores = model(inputs[None, :].to)\n",
        "    print(tag_scores.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "7BupB26MkqMW",
        "outputId": "314c1307-0de4-45f5-d323-753d2036ac89"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-242a366ca353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-de849ad20682>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpacked_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 'lengths' argument should be a 1D CPU int64 tensor, but got 0D cpu Long tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MmD2eenJimFl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}