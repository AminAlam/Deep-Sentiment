{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Sentiment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3VEjxTL2Muq",
        "outputId": "30298527-ddf6-4d55-d110-6a7a0a07d806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import spacy\n",
        "import random\n",
        "from pathlib import Path\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext import data \n",
        "import torchtext\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting device on GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_aKa0i90DNE",
        "outputId": "e2935959-1ef4-4379-b73b-03374d76d26e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Tesla K80\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:386: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading Dataset - Preprocessing on the Tweets"
      ],
      "metadata": {
        "id": "WsQEXhGRNHAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas_dir = r'/content/drive/My Drive/Courses/DeepLearning/HW03/Q01/Datas/train.csv'\n",
        "destination_folder = '/content/drive/My Drive/Courses/DeepLearning/HW03/Q01/Datas'"
      ],
      "metadata": {
        "id": "FYUGZGQGU_mj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(datas_dir, engine=\"python\", header=None)\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Uq5UljEbtmSv",
        "outputId": "548a6649-4328-4ce1-c434-47b0533e609b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6941cca4-1372-4585-91a7-b6011a60ba41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6941cca4-1372-4585-91a7-b6011a60ba41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6941cca4-1372-4585-91a7-b6011a60ba41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6941cca4-1372-4585-91a7-b6011a60ba41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   0  ...                                                  5\n",
              "0  0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1  0  ...  is upset that he can't update his Facebook by ...\n",
              "2  0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3  0  ...    my whole body feels itchy and like its on fire \n",
              "4  0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[0]=df[0].replace(to_replace=4,value=1)\n",
        "df[0].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaomRusYziSl",
        "outputId": "327e89e0-4275-4ee6-d24b-554cfb73bf40"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    800000\n",
              "0    800000\n",
              "Name: 0, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(50000).to_csv(\"sentiment140-small.csv\", header=None, index=None)"
      ],
      "metadata": {
        "id": "o0GD2nAdzlv5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = torchtext.legacy.data.Field(tokenize='spacy', lower=True, include_lengths= True)\n",
        "LABEL = torchtext.legacy.data.LabelField(dtype=torch.float)\n",
        "\n",
        "fields = [('label', LABEL), ('id',None),('date',None),('query',None),\n",
        "      ('name',None), ('text', TEXT),('category',None)]\n",
        "\n",
        "dataset = torchtext.legacy.data.TabularDataset(\n",
        "        path=\"sentiment140-small.csv\",\n",
        "        format=\"CSV\",\n",
        "        fields=fields,\n",
        "        skip_header=False)\n",
        "\n",
        "(train_data, test_data, valid_data) = dataset.split(split_ratio=[0.8,0.1,0.1])\n",
        "\n",
        "print(\"Number of train data: {}\".format(len(train_data)))\n",
        "print(\"Number of test data: {}\".format(len(test_data)))\n",
        "print(\"Number of validation data: {}\".format(len(valid_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BajJ_JKgwlYg",
        "outputId": "e9f2d369-857f-4bdd-856f-afd57c21ff77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train data: 40000\n",
            "Number of test data: 5000\n",
            "Number of validation data: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# An example from the training set\n",
        "print(vars(train_data.examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRyrGQbf1tMh",
        "outputId": "c70174a4-3198-44b0-8d0a-f9474b560843"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': '1', 'text': ['getting', 'ready', 'for', 'church', '...', 'cooking', 'out', 'later']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bulding Vocabulary"
      ],
      "metadata": {
        "id": "lwJWRD6g0rcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE,\n",
        "                 vectors = \"glove.6B.100d\",\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "TEXT.vocab.freqs.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoRWy5k_10lM",
        "outputId": "aa20f646-f96d-4195-b02c-82abac5a92ac"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 24910),\n",
              " ('!', 22553),\n",
              " ('.', 20134),\n",
              " (' ', 14450),\n",
              " ('to', 14175),\n",
              " ('the', 13027),\n",
              " (',', 12049),\n",
              " ('a', 9612),\n",
              " ('my', 7923),\n",
              " ('and', 7629)]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch = True)"
      ],
      "metadata": {
        "id": "GGagvCYQ17Ua"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model - LSTM"
      ],
      "metadata": {
        "id": "fTafSh9H104k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "\n",
        "        self.encoder = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
        "                                                  bidirectional=bidirectional,\n",
        "                                                  dropout=dropout)\n",
        "\n",
        "        self.predictor = nn.Linear(hidden_dim*2, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "      \n",
        "    def forward(self, text, text_lengths):\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text)) \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "\n",
        "\n",
        "        return self.predictor(hidden)"
      ],
      "metadata": {
        "id": "DPFaaI9r1-Ny"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 150\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = False\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model_1D = LSTM(INPUT_DIM,\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL,\n",
        "            DROPOUT,\n",
        "            PAD_IDX)\n",
        "\n",
        "BIDIRECTIONAL = True\n",
        "model_2D = LSTM(INPUT_DIM,\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL,\n",
        "            DROPOUT,\n",
        "            PAD_IDX)"
      ],
      "metadata": {
        "id": "hciii85Y2SaZ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model_1D.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "model_2D.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "re4L2Cm7CfAN",
        "outputId": "40f97f3b-d82d-4f65-8f5d-de332448ffbe"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.5870e-02,  1.7993e+00,  1.1746e+00,  ...,  6.0010e-01,\n",
              "          1.9139e+00, -1.6888e+00],\n",
              "        [-1.5553e+00,  1.3104e+00, -1.0326e+00,  ..., -1.1747e+00,\n",
              "         -6.6917e-01,  1.1146e+00],\n",
              "        [-4.6539e-02,  6.1966e-01,  5.6647e-01,  ..., -3.7616e-01,\n",
              "         -3.2502e-02,  8.0620e-01],\n",
              "        ...,\n",
              "        [-9.9313e-02,  9.0826e-01,  2.6145e-04,  ..., -7.1313e-01,\n",
              "          4.1456e-01, -7.9174e-01],\n",
              "        [ 4.7870e-01,  2.7702e+00, -1.2370e-01,  ..., -1.3711e-01,\n",
              "         -1.3272e-01, -2.6547e-01],\n",
              "        [ 4.6528e-01,  7.9971e-01,  6.9831e-01,  ...,  1.2706e+00,\n",
              "          4.5536e-01,  1.6046e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model_1D.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model_1D.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model_2D.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model_2D.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "bUHA1RoOI7iW"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper Functions"
      ],
      "metadata": {
        "id": "mVZV5XUaAd83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_accuracy(predictions, label):\n",
        "\n",
        "    preds = torch.round(torch.sigmoid(predictions))\n",
        "    correct = (preds == label).float()\n",
        "    accuracy = correct.sum() / len(correct)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "def timer(start_time, end_time):\n",
        "\n",
        "    time = end_time - start_time\n",
        "    mins = int(time / 60)\n",
        "    secs = int(time - (mins * 60))\n",
        "\n",
        "    return mins, secs\n",
        "    \n",
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    training_loss = 0.0\n",
        "    training_acc = 0.0\n",
        "    \n",
        "    model.train()\n",
        "     \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        text_lengths = text_lengths.cpu()\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "\n",
        "        accuracy = batch_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        training_loss += loss.item()\n",
        "        training_acc += accuracy.item()\n",
        "\n",
        "    return training_loss / len(iterator), training_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    eval_loss = 0.0\n",
        "    eval_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            text_lengths = text_lengths.cpu()\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            accuracy = batch_accuracy(predictions, batch.label)\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "            eval_acc += accuracy.item()\n",
        "        \n",
        "    return eval_loss / len(iterator), eval_acc / len(iterator)"
      ],
      "metadata": {
        "id": "igwY2GdQsBif"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the Model - 1 Direction"
      ],
      "metadata": {
        "id": "rbfK_mIM2Jc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model_1D.parameters(), lr=1e-3)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model_1D.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "qZsoLknRAZHt"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_1D, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    valid_loss, valid_acc = evaluate(model_1D, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    mins, secs = timer(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model-small.pt')\n",
        "\n",
        "    print(\"Epoch {}:\".format(epoch+1))\n",
        "    print(\"\\t Total Time: {}m {}s\".format(mins, secs))\n",
        "    print(\"\\t Train Loss {} | Train Accuracy: {}%\".format(round(train_loss, 2), round(train_acc*100, 2)))\n",
        "    print(\"\\t Validation Loss {} | Validation Accuracy: {}%\".format(round(valid_loss, 2), round(valid_acc*100, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI5q_FxVgdsy",
        "outputId": "98ef7661-58e9-405d-8f93-41afcc3cd785"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\t Total Time: 0m 5s\n",
            "\t Train Loss 0.55 | Train Accuracy: 72.39%\n",
            "\t Validation Loss 0.49 | Validation Accuracy: 75.92%\n",
            "Epoch 2:\n",
            "\t Total Time: 0m 4s\n",
            "\t Train Loss 0.49 | Train Accuracy: 76.27%\n",
            "\t Validation Loss 0.47 | Validation Accuracy: 77.97%\n",
            "Epoch 3:\n",
            "\t Total Time: 0m 4s\n",
            "\t Train Loss 0.46 | Train Accuracy: 78.92%\n",
            "\t Validation Loss 0.47 | Validation Accuracy: 77.52%\n",
            "Epoch 4:\n",
            "\t Total Time: 0m 5s\n",
            "\t Train Loss 0.43 | Train Accuracy: 80.47%\n",
            "\t Validation Loss 0.43 | Validation Accuracy: 80.92%\n",
            "Epoch 5:\n",
            "\t Total Time: 0m 5s\n",
            "\t Train Loss 0.4 | Train Accuracy: 81.86%\n",
            "\t Validation Loss 0.43 | Validation Accuracy: 80.62%\n",
            "Epoch 6:\n",
            "\t Total Time: 0m 4s\n",
            "\t Train Loss 0.38 | Train Accuracy: 83.2%\n",
            "\t Validation Loss 0.43 | Validation Accuracy: 80.25%\n",
            "Epoch 7:\n",
            "\t Total Time: 0m 5s\n",
            "\t Train Loss 0.37 | Train Accuracy: 83.82%\n",
            "\t Validation Loss 0.44 | Validation Accuracy: 80.27%\n",
            "Epoch 8:\n",
            "\t Total Time: 0m 5s\n",
            "\t Train Loss 0.35 | Train Accuracy: 85.21%\n",
            "\t Validation Loss 0.43 | Validation Accuracy: 81.07%\n",
            "Epoch 9:\n",
            "\t Total Time: 0m 5s\n",
            "\t Train Loss 0.33 | Train Accuracy: 85.85%\n",
            "\t Validation Loss 0.46 | Validation Accuracy: 79.69%\n",
            "Epoch 10:\n",
            "\t Total Time: 0m 5s\n",
            "\t Train Loss 0.31 | Train Accuracy: 86.52%\n",
            "\t Validation Loss 0.47 | Validation Accuracy: 80.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the Model - BiDirectional"
      ],
      "metadata": {
        "id": "vkhP0vtvBFrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model_2D.parameters(), lr=1e-3)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model_2D.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "9q880EHIBIoS"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model_2D, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    valid_loss, valid_acc = evaluate(model_2D, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    mins, secs = timer(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model-small.pt')\n",
        "\n",
        "    print(\"Epoch {}:\".format(epoch+1))\n",
        "    print(\"\\t Total Time: {}m {}s\".format(mins, secs))\n",
        "    print(\"\\t Train Loss {} | Train Accuracy: {}%\".format(round(train_loss, 2), round(train_acc*100, 2)))\n",
        "    print(\"\\t Validation Loss {} | Validation Accuracy: {}%\".format(round(valid_loss, 2), round(valid_acc*100, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGTFxUWFBLK_",
        "outputId": "9af70420-3a0b-4e14-9f52-169a7ec5f902"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\t Total Time: 0m 8s\n",
            "\t Train Loss 0.59 | Train Accuracy: 67.76%\n",
            "\t Validation Loss 0.5 | Validation Accuracy: 75.47%\n",
            "Epoch 2:\n",
            "\t Total Time: 0m 8s\n",
            "\t Train Loss 0.5 | Train Accuracy: 75.54%\n",
            "\t Validation Loss 0.47 | Validation Accuracy: 76.99%\n",
            "Epoch 3:\n",
            "\t Total Time: 0m 8s\n",
            "\t Train Loss 0.46 | Train Accuracy: 78.22%\n",
            "\t Validation Loss 0.47 | Validation Accuracy: 78.18%\n",
            "Epoch 4:\n",
            "\t Total Time: 0m 8s\n",
            "\t Train Loss 0.44 | Train Accuracy: 80.01%\n",
            "\t Validation Loss 0.43 | Validation Accuracy: 80.1%\n",
            "Epoch 5:\n",
            "\t Total Time: 0m 10s\n",
            "\t Train Loss 0.41 | Train Accuracy: 81.49%\n",
            "\t Validation Loss 0.44 | Validation Accuracy: 79.9%\n",
            "Epoch 6:\n",
            "\t Total Time: 0m 8s\n",
            "\t Train Loss 0.39 | Train Accuracy: 82.64%\n",
            "\t Validation Loss 0.44 | Validation Accuracy: 79.41%\n",
            "Epoch 7:\n",
            "\t Total Time: 0m 8s\n",
            "\t Train Loss 0.37 | Train Accuracy: 83.73%\n",
            "\t Validation Loss 0.44 | Validation Accuracy: 80.45%\n",
            "Epoch 8:\n",
            "\t Total Time: 0m 8s\n",
            "\t Train Loss 0.35 | Train Accuracy: 84.83%\n",
            "\t Validation Loss 0.44 | Validation Accuracy: 80.45%\n",
            "Epoch 9:\n",
            "\t Total Time: 0m 8s\n",
            "\t Train Loss 0.33 | Train Accuracy: 85.59%\n",
            "\t Validation Loss 0.45 | Validation Accuracy: 80.35%\n",
            "Epoch 10:\n",
            "\t Total Time: 0m 8s\n",
            "\t Train Loss 0.31 | Train Accuracy: 86.43%\n",
            "\t Validation Loss 0.46 | Validation Accuracy: 80.31%\n"
          ]
        }
      ]
    }
  ]
}